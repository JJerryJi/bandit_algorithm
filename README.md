# Reduction from Contextual Bandit to Linear Bandit
  -------------------- 

## Overall
  -------------------- 
This repo encapsulates the outcomes of my summer internship at the Algorithmic Research in Networked Information (ARNI), Department of Electrical and Computer Engineering - UCLA, under the mentorship of Professor Christina Fragouli and her PhD student Osama Hanna. The project received NSF grants with number #2007714  and #2221871.


## Background
 -------------------- 
 ### Bandit Problem Overivew
  --------------------
* The bandit problem is a foundational concept in decision theory and optimization, with direct relevance to reinforcement learning and machine learning.
* The multi-arm bandit framework proves to be a versatile tool for addressing a multitude of applications: personalized recommendation systems, clinical trial optimization, online advertising, and dynamic pricing.
 ### Linear Bandit Problem Setup:
   --------------------
* The learner will choose an action from a range of actions
* The learner will receive rewards based on their dot product with unknown parameter:
* The learner wants to maximize cumulative reward over sequential trials by intelligently selecting actions

### Contextual linear bandit v.s. Linear Bandit:
   --------------------
1. Contextual bandit considers changing dynamic action sets, where the available actions may change over time based on the context.
2. Contextual linear bandit is more challenging than the linear bandit in multiple setups
3. Therefore, more simpler algorithms have been developed for resolving linear bandit. 

  
## Motivation
  -------------------- 
Previously, our lab introduced a groundbreaking Reduction Algorithm to address the contextual linear bandit problem. This algorithm ingeniously simplifies the contextual problem to a linear bandit scenario, thus enabling existing and future linear bandit algorithms to tackle contextual bandit challenges. While the theoretical basis for this reduction algorithm was established, its practical efficacy remained unexplored.

## Project Scope
  -------------------- 
In this project, we embark on the practical implementation of the reduction framework from the ground up. Our primary objective is to assess its performance against conventional algorithms in contextual bandit scenarios. By employing the reduction technique, we aim to achieve similar levels of regret in contextual bandit setups as achieved by the state-of-the-art algorithms. The remarkable aspect is that we accomplish this using simpler algorithms originally designed for linear bandits. Surprisingly, our preliminary observations indicate that the reduction method yields **even lower regret** than traditional approaches in various instances.

### Repository Setup
  -------------------- 
In this repository, you'll find implementations of several algorithms that address the contextual bandit problem. The repository's structure includes:

- `LinUCB.py`: This module provides an implementation of the Linear Upper Confidence Bound (LinUCB) algorithm. The algorithm is encapsulated within a class, allowing for easy integration and experimentation.

- `UCB.py`: This module contains the implementation of the conventional Upper Confidence Bound (UCB) algorithm. Similar to LinUCB, the implementation is organized within a class structure.

- `phased_elimination.py`: This module presents the implementation of the Phased Elimination algorithm, a novel approach for batched learning and contextual bandit scenarios. The algorithm's functionality is encapsulated within a class for seamless integration.

- `angle.py`: This module presents the conversion of high-dimension vectors (n_dimension >=3) between Euculidean Coordinates to spherical coordinate, and vice-versa.

- `equal-sphere.py`: This module facilitates the generation of contextual action sets within sectors on an equal-sphere representation, designed specifically for contextual bandit problems.

- `comparsion.py`: This module facilitates in-depth comparisons of three contextual bandit methods: LinUCB with Reduction, standard LinUCB, and Phased Elimination with Reduction. It specializes in calculating, analyzing, and visually displaying the regret generated by these methods. This comparison sheds light on their relative performances

  
## Getting Started  
-------------------- 
To participate in our exploration of the Reduction Approach and its comparison against conventional algorithms, follow these steps:

### Prerequisites
-------------------- 
Ensure you have the following installed on your system:
- Python (>= 3.6)
- Required Python packages (as specified in `requirements.txt`)

### Installation
-------------------- 
1. Clone this repository:

   ```bash
   git clone https://github.com/yourusername/contextual-bandit-comparison.git
   python comparsion.py
